{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f70bc6-937b-46d4-bcd1-a25b18ae0cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /opt/conda did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/opt/conda/lib/python3.10/site-packages/cv2/../../lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a854e98d3a242cba4e3eed79a335ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jupyter/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /home/jupyter/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import viper_context\n",
    "from image_patch import ImagePatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1207c1b8-e0f4-4203-8717-5c2e80a6a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_unormalize(img):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).unsqueeze(1).unsqueeze(1) \n",
    "    var = torch.tensor([0.229, 0.224, 0.225]).unsqueeze(1).unsqueeze(1) \n",
    "    img = img*var + mean\n",
    "    return torch.tensor(img*255, dtype=torch.uint8)\n",
    "\n",
    "def imshow(img):\n",
    "    img = img_unormalize(img)\n",
    "    img = img.numpy().transpose(1, 2, 0)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544181ee-38b2-46bd-a432-3f3413be675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def execute_command(image) -> str:\n",
      "    image_patch = ImagePatch(image)\n",
      "    table_patches = image_patch.find(\"table\")\n",
      "    # Sort the tables from left to right\n",
      "    table_patches.sort(key=lambda x: x.left)\n",
      "    # Get the leftmost table\n",
      "    left_table = table_patches[0]\n",
      "    # Compute its depth\n",
      "    distance = left_table.compute_depth()\n",
      "    return f\"The table on the left is approximately {distance} units away.\"\n"
     ]
    }
   ],
   "source": [
    "api_file = 'gpt'\n",
    "with open(api_file) as f:\n",
    "    api_key = f.readline().splitlines()\n",
    "openai.api_key = api_key[0]\n",
    "\n",
    "query = 'Is there a coke bottle on top of the table?'\n",
    "query = 'What is on top of the table on the left?'\n",
    "query = 'How far is the table on the left?'\n",
    "\n",
    "\n",
    "prompt = viper_context.context.format(query=query)\n",
    "\n",
    "input_message = [\n",
    "    {\"role\": \"system\", \"content\": \"Only answer with a function starting def execute_command.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=input_message,\n",
    "    temperature=0,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=2.0,\n",
    "    stop=[\"\\\"\\\"\\\"\"])\n",
    "\n",
    "response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba0570f-e094-46c5-bf60-7590b3bc1e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:909: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table on the left is approximately 15 units away.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = \"imgs/example_image.png\"\n",
    "# image = cv2.imread(IMAGE_PATH)\n",
    "image = Image.open(IMAGE_PATH)\n",
    "# image_source, image = load_image(IMAGE_PATH)\n",
    "image_patch = ImagePatch(image)\n",
    "exec(response_message,globals())\n",
    "out = execute_command(image)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
